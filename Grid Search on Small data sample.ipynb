{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from modules import data_sampling, SimRank, evaluation, BenchMark\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "ratings_raw = pd.read_csv('ratings.csv')\n",
    "tags_raw = pd.read_csv('genome-scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_item = C_user = 0.9\n",
    "tag_relevance_cut_off = [0.1, 0.3, 0.5]\n",
    "lambdas = [0.3, 0.5, 0.7, 0.9]\n",
    "k_neighbors = [20, 40, 60, 80, 100]\n",
    "k_matric = [5, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_cos = SimRank.tag_simrank()\n",
    "tag_jac = SimRank.tag_simrank()\n",
    "wbs = SimRank.weighted_bipartite_simrank()\n",
    "cf = BenchMark.cf_recommendation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_k5 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ratings, tags = data_sampling.align_items(ratings_raw, tags_raw)\n",
    "rating_sample = data_sampling.sample_df(ratings, user_sample_n = 2000, item_sample_n = 200)\n",
    "rating_train, rating_test = train_test_split(rating_sample, test_size = 0.15, random_state = 42)\n",
    "\n",
    "user_grouped = evaluation.group(rating_test, 'user')\n",
    "\n",
    "cf.fit(\n",
    "    rating_train\n",
    ")\n",
    "tag_cos.fit(\n",
    "    rating_train, \n",
    "    tags, \n",
    "    C_item = C_item, \n",
    "    C_user = C_user, \n",
    "    lbd = 0.3\n",
    ")\n",
    "tag_jac.fit(\n",
    "    rating_train, \n",
    "    tags[tags.relevance > 0.1], \n",
    "    C_item = C_item, \n",
    "    C_user = C_user, \n",
    "    lbd = 0.3\n",
    ")\n",
    "wbs.fit(\n",
    "    rating_train, \n",
    "    C_item = C_item, \n",
    "    C_user = C_user\n",
    ")\n",
    "\n",
    "for lbd in lambdas:\n",
    "    S_user, S_item = tag_cos._cal_S(C_user, C_item, lbd, 100, 1e-4, GPU = False)\n",
    "    tag_cos.S_item = pd.DataFrame(S_item, index = tag_cos.items, columns = tag_cos.items)\n",
    "    tag_cos.S_user = pd.DataFrame(S_user, index = tag_cos.users, columns = tag_cos.users)\n",
    "    \n",
    "    for cutoff in tag_relevance_cut_off:\n",
    "        tag_jac.S_tag_based = tag_jac._cal_tab_based_S(tags[tags.relevance > cutoff], how = 'jac', GPU = False)\n",
    "        \n",
    "        S_user, S_item = tag_jac._cal_S(C_user, C_item, lbd, 100, 1e-4, GPU = False)\n",
    "        tag_jac.S_item = pd.DataFrame(S_item, index = tag_jac.items, columns = tag_jac.items)\n",
    "        tag_jac.S_user = pd.DataFrame(S_user, index = tag_jac.users, columns = tag_jac.users)\n",
    "            \n",
    "        for k in k_neighbors:\n",
    "            pred_tag_cos = tag_cos.cf_recommendation(rating_test, k = k)\n",
    "            pred_tag_jac = tag_jac.cf_recommendation(rating_test, k = k)\n",
    "            pred_wbs = wbs.cf_recommendation(rating_test, k = k)\n",
    "            pred_cf = cf.predict(rating_test, k = k)\n",
    "            \n",
    "            for n in k_matric:\n",
    "                precision_tag_cos, recall_tag_cos, ndcg_tag_cos = evaluation.evaluation_at_k(\n",
    "                    rating_test,\n",
    "                    pred_tag_cos,\n",
    "                    user_grouped = user_grouped,\n",
    "                    k = n\n",
    "                )\n",
    "                precision_tag_jac, recall_tag_jac, ndcg_tag_jac = evaluation.evaluation_at_k(\n",
    "                    rating_test,\n",
    "                    pred_tag_jac,\n",
    "                    user_grouped = user_grouped,\n",
    "                    k = n\n",
    "                )\n",
    "                precision_wbs, recall_wbs, ndcg_wbs = evaluation.evaluation_at_k(\n",
    "                    rating_test,\n",
    "                    pred_wbs,\n",
    "                    user_grouped = user_grouped,\n",
    "                    k = n\n",
    "                )\n",
    "                precision_cf, recall_cf, ndcg_cf = evaluation.evaluation_at_k(\n",
    "                    rating_test,\n",
    "                    pred_cf,\n",
    "                    user_grouped = user_grouped,\n",
    "                    k = n\n",
    "                )\n",
    "\n",
    "                records_k5.append({\n",
    "                    'lbd': lbd,\n",
    "                    'cutoff': cutoff, \n",
    "                    'k_neighbors': k,\n",
    "                    'k_matric': n,\n",
    "                    'precision_tag_cos': precision_tag_cos,\n",
    "                    'recall_tag_cos': recall_tag_cos,\n",
    "                    'ndcg_tag_cos': ndcg_tag_cos,\n",
    "                    'precision_tag_jac': precision_tag_jac,\n",
    "                    'recall_tag_jac': recall_tag_jac,\n",
    "                    'ndcg_tag_jac': ndcg_tag_jac,\n",
    "                    'precision_wbs': precision_wbs,\n",
    "                    'recall_wbs': recall_wbs,\n",
    "                    'ndcg_wbs': ndcg_wbs,\n",
    "                    'precision_cf': precision_cf,\n",
    "                    'recall_cf': recall_cf,\n",
    "                    'ndcg_cf': ndcg_cf\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rst = pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_big = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings, tags = data_sampling.align_items(ratings_raw, tags_raw)\n",
    "rating_sample = data_sampling.sample_df(ratings, item_thresh = 50, user_sample_n = 4000, item_sample_n = 1000)\n",
    "rating_train, rating_test = train_test_split(rating_sample, test_size = 0.15, random_state = 42)\n",
    "\n",
    "user_grouped = evaluation.group(rating_test, 'user')\n",
    "\n",
    "cf.fit(\n",
    "    rating_train\n",
    ")\n",
    "tag_cos.fit(\n",
    "    rating_train, \n",
    "    tags, \n",
    "    C_item = C_item, \n",
    "    C_user = C_user, \n",
    "    lbd = 0.3\n",
    ")\n",
    "tag_jac.fit(\n",
    "    rating_train, \n",
    "    tags[tags.relevance > 0.1], \n",
    "    C_item = C_item, \n",
    "    C_user = C_user, \n",
    "    lbd = 0.3\n",
    ")\n",
    "wbs.fit(\n",
    "    rating_train, \n",
    "    C_item = C_item, \n",
    "    C_user = C_user\n",
    ")\n",
    "\n",
    "for lbd in lambdas:\n",
    "    S_user, S_item = tag_cos._cal_S(C_user, C_item, lbd, 100, 1e-4, GPU = False)\n",
    "    tag_cos.S_item = pd.DataFrame(S_item, index = tag_cos.items, columns = tag_cos.items)\n",
    "    tag_cos.S_user = pd.DataFrame(S_user, index = tag_cos.users, columns = tag_cos.users)\n",
    "    \n",
    "    for cutoff in tag_relevance_cut_off:\n",
    "        tag_jac.S_tag_based = tag_jac._cal_tab_based_S(tags[tags.relevance > cutoff], how = 'jac', GPU = False)\n",
    "        \n",
    "        S_user, S_item = tag_jac._cal_S(C_user, C_item, lbd, 100, 1e-4, GPU = False)\n",
    "        tag_jac.S_item = pd.DataFrame(S_item, index = tag_jac.items, columns = tag_jac.items)\n",
    "        tag_jac.S_user = pd.DataFrame(S_user, index = tag_jac.users, columns = tag_jac.users)\n",
    "            \n",
    "        for k in k_neighbors:\n",
    "            pred_tag_cos = tag_cos.cf_recommendation(rating_test, k = k)\n",
    "            pred_tag_jac = tag_jac.cf_recommendation(rating_test, k = k)\n",
    "            pred_wbs = wbs.cf_recommendation(rating_test, k = k)\n",
    "            pred_cf = cf.predict(rating_test, k = k)\n",
    "            \n",
    "            for n in k_matric:\n",
    "                precision_tag_cos, recall_tag_cos, ndcg_tag_cos = evaluation.evaluation_at_k(\n",
    "                    rating_test,\n",
    "                    pred_tag_cos,\n",
    "                    user_grouped = user_grouped,\n",
    "                    k = n\n",
    "                )\n",
    "                precision_tag_jac, recall_tag_jac, ndcg_tag_jac = evaluation.evaluation_at_k(\n",
    "                    rating_test,\n",
    "                    pred_tag_jac,\n",
    "                    user_grouped = user_grouped,\n",
    "                    k = n\n",
    "                )\n",
    "                precision_wbs, recall_wbs, ndcg_wbs = evaluation.evaluation_at_k(\n",
    "                    rating_test,\n",
    "                    pred_wbs,\n",
    "                    user_grouped = user_grouped,\n",
    "                    k = n\n",
    "                )\n",
    "                precision_cf, recall_cf, ndcg_cf = evaluation.evaluation_at_k(\n",
    "                    rating_test,\n",
    "                    pred_cf,\n",
    "                    user_grouped = user_grouped,\n",
    "                    k = n\n",
    "                )\n",
    "\n",
    "                records_big.append({\n",
    "                    'lbd': lbd,\n",
    "                    'cutoff': cutoff, \n",
    "                    'k_neighbors': k,\n",
    "                    'k_matric': n,\n",
    "                    'precision_tag_cos': precision_tag_cos,\n",
    "                    'recall_tag_cos': recall_tag_cos,\n",
    "                    'ndcg_tag_cos': ndcg_tag_cos,\n",
    "                    'precision_tag_jac': precision_tag_jac,\n",
    "                    'recall_tag_jac': recall_tag_jac,\n",
    "                    'ndcg_tag_jac': ndcg_tag_jac,\n",
    "                    'precision_wbs': precision_wbs,\n",
    "                    'recall_wbs': recall_wbs,\n",
    "                    'ndcg_wbs': ndcg_wbs,\n",
    "                    'precision_cf': precision_cf,\n",
    "                    'recall_cf': recall_cf,\n",
    "                    'ndcg_cf': ndcg_cf\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rst_2000 = pd.DataFrame(records_k5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rst_4000 = pd.DataFrame(records_big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rst_2000[rst_2000.precision_tag_cos > rst_2000.precision_wbs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rst_4000[rst_4000.precision_tag_jac > rst_4000.precision_wbs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_user = rating_sample['userId'].nunique()\n",
    "n_item = rating_sample['movieId'].nunique()\n",
    "sparsity = round(1.0-len(rating_sample)/float(n_user * n_item), 5)\n",
    "\n",
    "print(f'number of users: {n_user}')\n",
    "print(f'number of items: {n_item}')\n",
    "print(f'sparsity: {sparsity * 100}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_by_time(df, test_size = 0.2):\n",
    "    train_df = df.groupby('userId').apply(lambda x: x.nsmallest(math.ceil(len(x) * (1 - test_size)), 'timestamp')).reset_index(drop = True)\n",
    "    test_df = df.groupby('userId').apply(lambda x: x.nlargest(math.floor(len(x) * test_size), 'timestamp')).reset_index(drop = True)\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20000 user, 1000 item, by timestamp\n",
    "rating_sample_time = data_sampling.sample_df(ratings)\n",
    "rating_train_time, rating_test_time = train_test_split_by_time(rating_sample_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1009114\n",
      "242268\n"
     ]
    }
   ],
   "source": [
    "print(len(rating_train_time))\n",
    "print(len(rating_test_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of users: 20000\n",
      "number of items: 1000\n",
      "sparsity: 93.743%\n"
     ]
    }
   ],
   "source": [
    "n_user = rating_sample_time['userId'].nunique()\n",
    "n_item = rating_sample_time['movieId'].nunique()\n",
    "sparsity = round(1.0-len(rating_sample_time)/float(n_user * n_item), 5)\n",
    "\n",
    "print(f'number of users: {n_user}')\n",
    "print(f'number of items: {n_item}')\n",
    "print(f'sparsity: {sparsity * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_grouped_time = evaluation.group(rating_test_time, 'user')\n",
    "\n",
    "cf.fit(\n",
    "    rating_train_time\n",
    ")\n",
    "tag_cos.fit(\n",
    "    rating_train_time, \n",
    "    tags, \n",
    "    C_item = C_item, \n",
    "    C_user = C_user, \n",
    "    lbd = 0.3\n",
    ")\n",
    "tag_jac.fit(\n",
    "    rating_train_time, \n",
    "    tags[tags.relevance > 0.1], \n",
    "    C_item = C_item, \n",
    "    C_user = C_user, \n",
    "    lbd = 0.3\n",
    ")\n",
    "wbs.fit(\n",
    "    rating_train_time, \n",
    "    C_item = C_item, \n",
    "    C_user = C_user\n",
    ")\n",
    "\n",
    "for lbd in lambdas:\n",
    "    S_user, S_item = tag_cos._cal_S(C_user, C_item, lbd, 100, 1e-4, GPU = False)\n",
    "    tag_cos.S_item = pd.DataFrame(S_item, index = tag_cos.items, columns = tag_cos.items)\n",
    "    tag_cos.S_user = pd.DataFrame(S_user, index = tag_cos.users, columns = tag_cos.users)\n",
    "    \n",
    "    for cutoff in tag_relevance_cut_off:\n",
    "        tag_jac.S_tag_based = tag_jac._cal_tab_based_S(tags[tags.relevance > cutoff], how = 'jac', GPU = False)\n",
    "        \n",
    "        S_user, S_item = tag_jac._cal_S(C_user, C_item, lbd, 100, 1e-4, GPU = False)\n",
    "        tag_jac.S_item = pd.DataFrame(S_item, index = tag_jac.items, columns = tag_jac.items)\n",
    "        tag_jac.S_user = pd.DataFrame(S_user, index = tag_jac.users, columns = tag_jac.users)\n",
    "            \n",
    "        for k in k_neighbors:\n",
    "            pred_tag_cos = tag_cos.cf_recommendation(rating_test_time, k = k)\n",
    "            pred_tag_jac = tag_jac.cf_recommendation(rating_test_time, k = k)\n",
    "            pred_wbs = wbs.cf_recommendation(rating_test_time, k = k)\n",
    "            pred_cf = cf.predict(rating_test_time, k = k)\n",
    "            \n",
    "            for n in k_matric:\n",
    "                precision_tag_cos, recall_tag_cos, ndcg_tag_cos = evaluation.evaluation_at_k(\n",
    "                    rating_test_time,\n",
    "                    pred_tag_cos,\n",
    "                    user_grouped = user_grouped_time,\n",
    "                    k = n\n",
    "                )\n",
    "                precision_tag_jac, recall_tag_jac, ndcg_tag_jac = evaluation.evaluation_at_k(\n",
    "                    rating_test_time,\n",
    "                    pred_tag_jac,\n",
    "                    user_grouped = user_grouped_time,\n",
    "                    k = n\n",
    "                )\n",
    "                precision_wbs, recall_wbs, ndcg_wbs = evaluation.evaluation_at_k(\n",
    "                    rating_test_time,\n",
    "                    pred_wbs,\n",
    "                    user_grouped = user_grouped_time,\n",
    "                    k = n\n",
    "                )\n",
    "                precision_cf, recall_cf, ndcg_cf = evaluation.evaluation_at_k(\n",
    "                    rating_test_time,\n",
    "                    pred_cf,\n",
    "                    user_grouped = user_grouped_time,\n",
    "                    k = n\n",
    "                )\n",
    "\n",
    "                records_big.append({\n",
    "                    'lbd': lbd,\n",
    "                    'cutoff': cutoff, \n",
    "                    'k_neighbors': k,\n",
    "                    'k_matric': n,\n",
    "                    'precision_tag_cos': precision_tag_cos,\n",
    "                    'recall_tag_cos': recall_tag_cos,\n",
    "                    'ndcg_tag_cos': ndcg_tag_cos,\n",
    "                    'precision_tag_jac': precision_tag_jac,\n",
    "                    'recall_tag_jac': recall_tag_jac,\n",
    "                    'ndcg_tag_jac': ndcg_tag_jac,\n",
    "                    'precision_wbs': precision_wbs,\n",
    "                    'recall_wbs': recall_wbs,\n",
    "                    'ndcg_wbs': ndcg_wbs,\n",
    "                    'precision_cf': precision_cf,\n",
    "                    'recall_cf': recall_cf,\n",
    "                    'ndcg_cf': ndcg_cf\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
